abline(v=media1,col="red")
abline(v=mediana1, col="blue")
hist(maq2,col="pink", xlim=c(310,400))
abline(v=media2,col="red")
abline(v=mediana2, col="blue")
par(mfrow=c(2,1))
##  graficar los histogramas
hist(maq1,col="cyan", xlim=c(310,400))
abline(v=media1,col="red")
abline(v=mediana1, col="blue")
hist(maq2,col="pink", xlim=c(310,400))
abline(v=media2,col="red")
abline(v=mediana2, col="blue")
par(mfrow=c(1,1))
boxplot(Vol ~ Maq, data=maquinas, col=c("cyan", "pink"))
media1
mediana1
par(mfrow=c(1,1))
boxplot(Vol ~ Maq, data=maquinas, col=c("cyan", "pink"))
advertising =  read.table("clipboard", header=T) # Windows
advertising =  read.table("clipboard", header=T) # Windows
plot(advertising)
dim(advertising)
set.seed(666)
muestra = sample(1:200, 30, replace=F)
muestra
train =  advertising[-muestra,]
train
test  =  advertising[muestra,]
modelo1 =  lm(Sales ~ TV + Radio + Newspaper, data=train)
summary(modelo1)
modelo2 =  lm(Sales ~ TV + Radio, data = train)
summary(modelo2)
pred = predict(modelo2, newdata=test)
sum((pred - test$Sales)^2)
plot(pred, test$Sales)
plot(advertising)
pred = predict(modelo2, newdata=test)
modelo1 =  lm(Sales ~ TV + Radio + Newspaper, data=train)
summary(modelo1)
modelo2 =  lm(Sales ~ TV + Radio, data = train)
summary(modelo2)
pred = predict(modelo2, newdata=test)
sum((pred - test$Sales)^2)
plot(pred, test$Sales)
modelo3 = lm(Sales ~ TV, data=train)
summary(modelo3)
pred2 = predict(modelo3, newdata=test)
sum((pred2 - test$Sales)^2)
plot(pred2, test$Sales)
radio = 60
tele = 250
dato = data.frame(TV = tele, Radio = radio)
predict(modelo2, newdata=dato)
plot(pred, test$Sales)
sum((pred - test$Sales)^2)
plot(advertising)
summary(modelo1)
plot(pred, test$Sales)
predict(modelo2, newdata=dato)
dato
fecha1 = '2022-01-01'
fecha1
fecha2 = as.Date(fecha1)
fechas <- seq(as.Date("2018-01-01"), as.Date("2018-06-30"), by="2 months")
head(fechas)
length(fechas)
diasdevida <- seq(as.Date("1980-01-01"), as.Date("2020-7-30"), by="1 days")
head(diasdevida)
length(diasdevida)
chupidays <- seq(as.Date('2001-01-02'), as.Date('2022-10-14'), by="1 days")
head(chupidays)
length(chupidays)
secfechas <- seq(as.Date("2001-07-02"), length=50, by="months")
head(secfechas)
length(secfechas)
length(chupidays)
vec1 = 1:100
## Generemos una serie mensual
serie1 <- ts(vec1, start=c(2020,7),frequency=12)
serie1
## Generemos una serie trimestral
serie2 =  ts(vec1, start=c(2020,1),frequency=4)
serie2
install.packages("lubridate")
library(lubridate)
wday(diasdevida[2384],label=T)
wday(diasdevida[2384])
wday(as.Date("2020-07-30"),label=T)
wday(diasdevida[2384],label=T)
wday(as.Date(now("GMT")))
wday(as.Date("2001-01-02"))
dmy("1/7/2020")
mdy("7/1/2020")
ymd("2020/7/1")
ydm("2020/1/7")
dmy("1-7-2020")
dmy("1 jul 2020")
dmy("1/7/2020") + days(45)
dmy("1/7/2020") + weeks(10)
dmy("1/7/2020") + months(5)
secuencia1 <- seq(as.Date("2014-07-13"), as.Date("2020-07-30"), by="1 weeks")
head(secuencia1)
secuencia2 <- format(secuencia1, "%d/%m/%Y")
head(secuencia2)
nacimientos <- scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
plot.ts(stnacimientos)
stnacimientos <- ts(nacimientos, frequency=12, start=c(1946,1))
plot.ts(stnacimientos)
stnacimientoscomp <- decompose(stnacimientos)
plot(stnacimientoscomp)
nacpred <- HoltWinters(stnacimientos)
nacpred
## Plotear la serie original junto con el modelo HoltWinters
plot(nacpred)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 12, prediction.interval = T, level = 0.95)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 12, prediction.interval = T, level = 0.95)
## Plotear la serie y el pronostico
plot(nacpred, pronostico1)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 48, prediction.interval = T, level = 0.95)
## Plotear la serie y el pronostico
plot(nacpred, pronostico1)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 3, prediction.interval = T, level = 0.95)
## Plotear la serie y el pronostico
plot(nacpred, pronostico1)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 3, prediction.interval = T, level = 0.95)
## Plotear la serie y el pronostico
plot(nacpred, pronostico1)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 12, prediction.interval = T, level = 0.95)
## Plotear la serie y el pronostico
plot(nacpred, pronostico1)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 24, prediction.interval = T, level = 0.95)
## Plotear la serie y el pronostico
plot(nacpred, pronostico1)
## hacer un pronostico de la serie para 12 meses
pronostico1 <- predict(nacpred, n.ahead = 3, prediction.interval = T, level = 0.95)
## Plotear la serie y el pronostico
plot(nacpred, pronostico1)
library(forecast)
ventas <- read.table(file="clipboard",header=T)
ventas <- read.table(file="clipboard",header=T)
ventas <- read.table(file="clipboard",header=T)
head(ventas)
serieVentas <- ts(ventas$Sales,start=2002,frequency=12)
serieVentas
plot.ts(serieVentas)
componentes <- decompose(serieVentas)
plot(componentes)
numpred <- 12
pronostico = forecast(serieVentas, numpred)
plot(pronostico)
plot(componentes)
maquinas <- read.table(file="clipboard", header=T)
produccion <- read.table(file="clipboard", header=T)
head(maquinas, 10)
produccion <- read.table(file="clipboard", header=T)
head(produccion, 10)
serie1 <- ts(vec1, start=c(1962,1),frequency=12)
serie1''
serie1
source("~/.active-rstudio-document", echo=TRUE)
serie1 <- ts(produccion$milk, start=c(1962,1),frequency=12)
serie1 <- ts(produccion$Milk, start=c(1962,1),frequency=12)
head(produccion, 10)
produccion
produccion <- read.table(file="clipboard", header=T)
produccion
produccion$Milk
produccion$Month.mil
produccion$Month.Milk
produccion <- read.table(file="clipboard", header=T)
produccion <- read.table(file="clipboard", header=T)
serie1 <- ts(produccion, start=c(1962,1),frequency=12)
serie1
plo.ts(serie1)
plot.ts(serie1)
produccion <- read.table(file="clipboard", header=T)
head(produccion, 10)
serie1 <- ts(produccion$Milk, start=c(1962,1),frequency=12)
plot.ts(serie1)
serie1
decompose(serie1)
library(forecast)
decompose(serie1)
decomposed <- decompose(serie1)
plot(decomposed)
## Grafico
plot.ts(serie1)
plot.ts(serieVentas)
componentes <- decompose(serieVentas)
plot(componentes)
plot(decomposed)
## Grafico
plot.ts(serie1)
plot(decomposed)
plot(componentes)
plot(decomposed)
## Grafico
plot.ts(serie1)
plot(decomposed)
library(forecast)
prediction_months <- 12
forecast(serie1, prediction_months)
forecast <- forecast(serie1, prediction_months)
plot(forecast)
forecast
plot(forecast)
ar <- auto.arima(forecast)
ar <- auto.arima(serie1)
plot(ar)
ar <- auto.arima(serie1)
plot(ar)
pronosticoArima <- forecast(ar, numpred)
plot(pronosticoArima)
plot(forecast)
## HoltWinters
venpred <- HoltWinters(serie1)
plot(holtPred)
## HoltWinters
holtPred <- HoltWinters(serie1)
plot(holtPred)
fcHolt <- forecast(holtPred, numpred)
plot(fcHolt)
accuracy(fcHolt)
accuracy(forecast)
accuracy(pronosticoArima)
accuracy(forecast)
accuracy(pronosticoArima)
accuracy(fcHolt)
install.packages("tidyverse")
ToothGrowth
qqnorm(ToothGrowth$len)
qqline(ToothGrowth$len, col="red")
shapiro.test(ToothGrowth$len)
setwd("C:/Users/Daniel/Main/UVG/Semestre VII/Minería de datos/HT1")
knitr::opts_chunk$set(echo = TRUE)
films <- read.csv("movies.csv")
shapiro.test(films$bugdet)
films$budget
sum(is.na(films$budget))
films$budget
shapiro.test(films$bugdet)
class(films$budget)
shapiro.test(as.numeric(films$budget))
budget <- as.numeric(films$budget)
lillie.test(budget)
library(nortest)
lillie.test(budget)
lillie.test(films$budget)
shapiro.test(films$runtime)
shapiro.test(films[1:5000, films$runtime])
shapiro.test(films[films$runtime, 1:5000])
films[films$runtime,]
films[,films$runtime]
films[,1:5000]$runtime
films[1:5000,]$runtime
shapiro.test(films[1:5000,]$runtime)
head(films$popularity)
films$popularity
ordered <- films[order(films$budget, decreasing=T),]
firstTenMovies <- ordered[1:10,]
firstTenMovies[, c("title", "budget")]
head(iris)
install.packages("rlang")
install.packages("rlang")
setwd("C:/Users/Daniel/Main/UVG/Semestre VII/Minería de datos/proyecto")
library(nortest)
library(dplyr)
library(hopkins)
library(factoextra)
library(ggrepel)
library(cluster)
library(flexclust)
library(FeatureImpCluster)
library(stringr)
library(tidyr)
library(stats)
library(graphics)
library(NbClust)
library(mclust)
library(GGally)
library(corrplot)
library(caret)
library(ggplot2)
library(kableExtra)
library(e1071)
library(rpart)
library(rpart.plot)
library(naivebayes)
library(randomForest)
library(RColorBrewer)
library(ca)
library(vcd)
library(xgboost)
library(mlr)
library(glmnet)
datos <- read.csv("defun_nac.csv")
datos$SEXO <- ifelse(datos$SEXO == 9, NA, datos$SEXO)
datos$SEMGES <- ifelse(datos$SEMGES == 99, NA, datos$SEMGES)
datos$EDADM <- ifelse(datos$EDADM == 999, NA, datos$EDADM)
datos$DEPREM <- ifelse(datos$DEPREM == 9999, NA, datos$DEPREM)
datos$MUPREM <- ifelse(datos$MUPREM == 9999, NA, datos$MUPREM)
datos$ESCIVM <- ifelse(datos$ESCIVM == 9, NA, datos$ESCIVM)
datos$ESCOLAM <- ifelse(datos$ESCOLAM == 9, NA, datos$ESCOLAM)
datos$SITIOOCU <- ifelse(datos$SITIOOCU == 9, NA, datos$SITIOOCU)
datos$TOHITE <- ifelse(datos$TOHITE == 99, NA, datos$TOHITE)
datos$TOHINM <- ifelse(datos$TOHINM == 99, NA, datos$TOHINM)
datos$TOHIVI <- ifelse(datos$TOHIVI == 99, NA, datos$TOHIVI)
cualitativas <- c('DEPREG', 'MUPREG', 'MESREG', 'AÑOREG', 'DEPOCU', 'MUPOCU', 'SEXO', 'DIAOCU', 'MESOCU', 'TIPAR', 'DEPREM', 'MUPREM', 'ESCIVM', 'ESCOLAM', 'ASISREC', 'SITIOOCU', 'TIPO')
datos[, cualitativas] <- lapply(datos[, cualitativas], as.factor)
datos <- na.omit(datos)
datos <- select(datos, -SEMGES, -MUPREG, -MUPOCU, -DEPOCU, -MUPREM, -DEPREG, -DEPREM, -TOHITE, -AÑOREG)
# colnames(datos)[2] <- 'ANOREG'
library(nortest)
library(dplyr)
library(hopkins)
library(factoextra)
library(ggrepel)
library(cluster)
library(flexclust)
library(FeatureImpCluster)
library(stringr)
library(tidyr)
library(stats)
library(graphics)
library(NbClust)
library(mclust)
library(GGally)
library(corrplot)
library(caret)
library(ggplot2)
library(kableExtra)
library(e1071)
library(rpart)
library(rpart.plot)
library(naivebayes)
library(randomForest)
library(RColorBrewer)
library(ca)
library(vcd)
library(xgboost)
library(mlr)
library(glmnet)
datos <- read.csv("defun_nac.csv")
datos$SEXO <- ifelse(datos$SEXO == 9, NA, datos$SEXO)
datos$SEMGES <- ifelse(datos$SEMGES == 99, NA, datos$SEMGES)
datos$EDADM <- ifelse(datos$EDADM == 999, NA, datos$EDADM)
datos$DEPREM <- ifelse(datos$DEPREM == 9999, NA, datos$DEPREM)
datos$MUPREM <- ifelse(datos$MUPREM == 9999, NA, datos$MUPREM)
datos$ESCIVM <- ifelse(datos$ESCIVM == 9, NA, datos$ESCIVM)
datos$ESCOLAM <- ifelse(datos$ESCOLAM == 9, NA, datos$ESCOLAM)
datos$SITIOOCU <- ifelse(datos$SITIOOCU == 9, NA, datos$SITIOOCU)
datos$TOHITE <- ifelse(datos$TOHITE == 99, NA, datos$TOHITE)
datos$TOHINM <- ifelse(datos$TOHINM == 99, NA, datos$TOHINM)
datos$TOHIVI <- ifelse(datos$TOHIVI == 99, NA, datos$TOHIVI)
cualitativas <- c('DEPREG', 'MUPREG', 'MESREG', 'AÑOREG', 'DEPOCU', 'MUPOCU', 'SEXO', 'DIAOCU', 'MESOCU', 'TIPAR', 'DEPREM', 'MUPREM', 'ESCIVM', 'ESCOLAM', 'ASISREC', 'SITIOOCU', 'TIPO')
datos[, cualitativas] <- lapply(datos[, cualitativas], as.factor)
datos <- na.omit(datos)
datos <- select(datos, -SEMGES, -MUPREG, -MUPOCU, -DEPOCU, -MUPREM, -DEPREG, -DEPREM, -TOHITE, -AÑOREG)
# colnames(datos)[2] <- 'ANOREG'
porcentaje <- 0.7
set.seed(123)
corte <- sample(nrow(datos), nrow(datos) * porcentaje)
train <- datos[corte, ]
test <- datos[-corte, ]
set.seed(123)
train1$TIPO <- train$TIPO
set.seed(123)
data <- datos
cualitativas2 <- c('MESREG', 'AÑOREG', 'SEXO', 'DIAOCU', 'MESOCU', 'TIPAR', 'ESCIVM', 'ESCOLAM', 'ASISREC', 'SITIOOCU')
cualitativas2_indices <- which(colnames(data) %in% cualitativas2)
data$TIPO <- ifelse(data$TIPO == "muerto", 1, 0)
encoding_model <- dummyVars(~., data = data[, cualitativas2_indices], fullRank = TRUE)
encoded_data <- predict(encoding_model, newdata = data[, cualitativas2_indices])
final_data <- cbind(data[, !cualitativas2_indices], encoded_data)
final_data$TIPO <- data$TIPO
porcentaje <- 0.7
corte <- sample(nrow(final_data), nrow(final_data) * porcentaje)
train1 <- final_data[corte, ]
test1 <- final_data[-corte, ]
set.seed(123)
train1$TIPO <- train$TIPO
task <- makeClassifTask(data = train1, target = "TIPO")
param_grid <- makeParamSet(
makeDiscreteParam("nrounds", values = seq(100, 500, by = 20)),
makeIntegerParam("max_depth", lower = 3, upper = 10),
makeNumericParam("eta", lower = 0.01, upper = 0.3)
)
control_tune <- makeTuneControlRandom(maxit = 30)
resampling <- makeResampleDesc("CV", iters = 5)
measure <- acc
tuned_model <- tuneParams(
learner = "classif.xgboost",  # For classification, use "classif.xgboost"; for regression, use "regr.xgboost"
task = task,
resampling = resampling,
measures = measure,
par.set = param_grid,
control = control_tune,
show.info = TRUE
)
xgb_model <- xgboost(data = as.matrix(train1[, -which(colnames(train1) == "TIPO")]),
label = train1[, c('TIPO')],
nrounds = 500, max_depth=4, eta=0.2254931, verbose=0)
# Make predictions
predictions <- predict(xgb_model, as.matrix(test1[, -which(colnames(test1) == "TIPO")]))
predictions <- ifelse(predictions > 0.5, 1, 0)
predictions <- factor(predictions)
# datos2 <- as.data.frame(datos2)
# datos2$TIPO <- factor(datos2$TIPO, levels = c('0', '1'))
# datos2$TIPO
confusion_matrix <- confusionMatrix(reference = as.factor(test1$TIPO), data = predictions)
confusion_matrix
train1$TIPO <- train$TIPO
xgb_model <- xgboost(data = as.matrix(train1[, -which(colnames(train1) == "TIPO")]),
label = train1[, c('TIPO')],
nrounds = 500, max_depth=4, eta=0.2254931, verbose=0)
# Make predictions
predictions <- predict(xgb_model, as.matrix(test1[, -which(colnames(test1) == "TIPO")]))
predictions <- ifelse(predictions > 0.5, 1, 0)
predictions <- factor(predictions)
# datos2 <- as.data.frame(datos2)
# datos2$TIPO <- factor(datos2$TIPO, levels = c('0', '1'))
# datos2$TIPO
confusion_matrix <- confusionMatrix(reference = as.factor(test1$TIPO), data = predictions)
confusion_matrix
head(train1$TIPO)
library(nortest)
library(dplyr)
library(hopkins)
library(factoextra)
library(ggrepel)
library(cluster)
library(flexclust)
library(FeatureImpCluster)
library(stringr)
library(tidyr)
library(stats)
library(graphics)
library(NbClust)
library(mclust)
library(GGally)
library(corrplot)
library(caret)
library(ggplot2)
library(kableExtra)
library(e1071)
library(rpart)
library(rpart.plot)
library(naivebayes)
library(randomForest)
library(RColorBrewer)
library(ca)
library(vcd)
library(xgboost)
library(mlr)
library(glmnet)
datos <- read.csv("defun_nac.csv")
datos$SEXO <- ifelse(datos$SEXO == 9, NA, datos$SEXO)
datos$SEMGES <- ifelse(datos$SEMGES == 99, NA, datos$SEMGES)
datos$EDADM <- ifelse(datos$EDADM == 999, NA, datos$EDADM)
datos$DEPREM <- ifelse(datos$DEPREM == 9999, NA, datos$DEPREM)
datos$MUPREM <- ifelse(datos$MUPREM == 9999, NA, datos$MUPREM)
datos$ESCIVM <- ifelse(datos$ESCIVM == 9, NA, datos$ESCIVM)
datos$ESCOLAM <- ifelse(datos$ESCOLAM == 9, NA, datos$ESCOLAM)
datos$SITIOOCU <- ifelse(datos$SITIOOCU == 9, NA, datos$SITIOOCU)
datos$TOHITE <- ifelse(datos$TOHITE == 99, NA, datos$TOHITE)
datos$TOHINM <- ifelse(datos$TOHINM == 99, NA, datos$TOHINM)
datos$TOHIVI <- ifelse(datos$TOHIVI == 99, NA, datos$TOHIVI)
cualitativas <- c('DEPREG', 'MUPREG', 'MESREG', 'AÑOREG', 'DEPOCU', 'MUPOCU', 'SEXO', 'DIAOCU', 'MESOCU', 'TIPAR', 'DEPREM', 'MUPREM', 'ESCIVM', 'ESCOLAM', 'ASISREC', 'SITIOOCU', 'TIPO')
datos[, cualitativas] <- lapply(datos[, cualitativas], as.factor)
datos <- na.omit(datos)
datos <- select(datos, -SEMGES, -MUPREG, -MUPOCU, -DEPOCU, -MUPREM, -DEPREG, -DEPREM, -TOHITE, -AÑOREG)
# colnames(datos)[2] <- 'ANOREG'
porcentaje <- 0.7
set.seed(123)
corte <- sample(nrow(datos), nrow(datos) * porcentaje)
train <- datos[corte, ]
test <- datos[-corte, ]
set.seed(123)
data <- datos
cualitativas2 <- c('MESREG', 'AÑOREG', 'SEXO', 'DIAOCU', 'MESOCU', 'TIPAR', 'ESCIVM', 'ESCOLAM', 'ASISREC', 'SITIOOCU')
cualitativas2_indices <- which(colnames(data) %in% cualitativas2)
data$TIPO <- ifelse(data$TIPO == "muerto", 1, 0)
encoding_model <- dummyVars(~., data = data[, cualitativas2_indices], fullRank = TRUE)
encoded_data <- predict(encoding_model, newdata = data[, cualitativas2_indices])
final_data <- cbind(data[, !cualitativas2_indices], encoded_data)
final_data$TIPO <- data$TIPO
porcentaje <- 0.7
corte <- sample(nrow(final_data), nrow(final_data) * porcentaje)
train1 <- final_data[corte, ]
test1 <- final_data[-corte, ]
head(train1$TIPO)
# train1$TIPO <- train$TIPO
xgb_model <- xgboost(data = as.matrix(train1[, -which(colnames(train1) == "TIPO")]),
label = train1[, c('TIPO')],
nrounds = 500, max_depth=4, eta=0.2254931, verbose=0)
# Make predictions
predictions <- predict(xgb_model, as.matrix(test1[, -which(colnames(test1) == "TIPO")]))
predictions <- ifelse(predictions > 0.5, 1, 0)
predictions <- factor(predictions)
# datos2 <- as.data.frame(datos2)
# datos2$TIPO <- factor(datos2$TIPO, levels = c('0', '1'))
# datos2$TIPO
confusion_matrix <- confusionMatrix(reference = as.factor(test1$TIPO), data = predictions)
confusion_matrix
